\paragraph{}
To extract HOG features from the input image we used a function provided by \textbf{scikit-image} package in python, as for the parameters we only tuned the normalization method parameter, as for the rest of parameters were taken following a paper\cite{hog} which compared between other different parameters and gave us insights on the best ones to use.\newline 
our final configuration: \newline
\begin{itemize}
\item Orientation: 8 bins. 
\item 12X12 pixels per cell. 
\item 4X4 cells per block.
\end{itemize}

\paragraph{Normalization parameter tuning}
we tried different normalization methods on the different datasets we had and chose the one that gave a better result on average.

\begin{center}
\begin{tabular}{ c|c|c|c }
	  & FER & CK+ & RafD \\ \hline
	 L1-norm & 23.16\% & 36.11\% & 89.08\% \\  
	 L2-norm & 36.80\% & 57.33\% & \textbf{90.2\%} \\
	 L1-sqrt & \textbf{38.61\%} & 46.83\% & 89.21\% \\
	 L2-Hys & \textbf{38.61\%} & \textbf{57.99\%} & 88.96\% \\
\end{tabular}
\end{center}
With FER \textbf{L1-sqrt} and \textbf{L2-Hys} give best result.\newline
With CK+ we choose to work with  .\newline
With RafD we choose to work with  \textbf{L2-norm}. \newline
\paragraph{}
as obvious from the results \textbf{L1-sqrt} and \textbf{L2-Hys} methods tend to show better results on average, but \textbf{L2-Hys} seems to be more effective method.
\newline \newline We also tried hog with sliding window to increase accuracy in case of using FER dataset, it captures more features than normal hog by passing window throughout the whole image and apply hog to pixels but unfortunately we got test accuracy XX so we decided to not use it for the rest datasets.

