Facial Expression Recognition is one of the most challenging problems in machine learning, many scientific papers and projects were made to tackle this challenge over the past few years.\newline
but what impact can the ability to recognize Facial Expression Recognition achieve?, The idea is to make the machines recognize the emotions of humans leads to better understanding and stronger means of communication between both, which can create a huge leap in machines perceived intelligence.\newline
\bigbreak

Companies have been taking advantage of emotion recognition to drive business outcomes, For the upcoming release of Toy Story 5, Disney plans to use facial recognition to judge the emotional responses of the audience, Apple even released a new feature on the iPhone X called Animoji, where you can get a computer simulated emoji to mimic your facial expressions, It’s not so far off to assume they’ll use those capabilities in other applications soon, in the feature we may see more advanced applications for this topic, for example, a Facial recognition can be used by a therapist during sessions to track the mental state of patients and get better insights about their progress, marketing companies can use it as well to measure the satisfaction and in-satisfaction about the products they present, it can be used within companies to track the mental state of the employees to help improve work productivity.
\bigbreak
We have checked multiple other project working on same topic but didn't find a satisfactory answer as to what is the best way to detect emotions in real time? what best performance that can be reached and how? the compromise between real time operation and accuracy?, for this reason we started this project with the purpose of answering these questions.
\newpage

